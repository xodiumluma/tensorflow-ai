// RUN: fusion_to_mlir %s | FileCheck %s
// RUN: test_correctness %s

add {
  scalar_lhs.0 = f32[] parameter(0)
  scalar_lhs.1 = f32[] parameter(1)
  scalar_rhs.0 = f32[] parameter(2)
  scalar_rhs.1 = f32[] parameter(3)
  add = f32[] add(scalar_lhs.0, scalar_rhs.0)
  mul = f32[] multiply(scalar_lhs.1, scalar_rhs.1)
  ROOT t = (f32[], f32[]) tuple(add, mul)
}

fused_computation {
  param_0 = f32[3,4,5] parameter(0)
  param_1 = f32[3,4,5] parameter(1)
  c = f32[] constant(0)
  ROOT d.1 = (f32[4], f32[4]) reduce(param_0, param_1, c, c), dimensions={0,2},
      to_apply=add
}

// CHECK: func @main(
// CHECK:   %[[TID_X:.*]] = gpu.thread_id x
// CHECK:   %[[SCALARS_0:.*]], %[[SCALARS_1:.*]] = xla_gpu.pure_call @fused_computation_d_1
// CHECK:   %[[INSERTED_1:.*]] = tensor.insert %[[SCALARS_0]] into %{{.*}}[%[[TID_X]]]
// CHECK:   %[[INSERTED_2:.*]] = tensor.insert %[[SCALARS_1]] into %{{.*}}[%[[TID_X]]]
// CHECK:   return %[[INSERTED_1]], %[[INSERTED_2]]

// CHECK: func private @fused_computation_d_1
// CHECK:   %[[RET:.*]]:2 = func.call @add_t
// CHECK:   yield %[[RET]]#0, %[[RET]]#1
